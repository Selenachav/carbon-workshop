{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NPFE Data with CSV on the Web\n",
    "\n",
    "This notebooks exemplifies how data about [new particle formation events](http://purl.obolibrary.org/obo/ENVO_01001372) can be described using [CSV on the Web](https://www.w3.org/TR/2015/REC-tabular-data-model-20151217/). \n",
    "\n",
    "We interpret particle size distribution data (primary data) as measured by an observation system of the [SMEAR](https://www.atm.helsinki.fi/SMEAR/) research infrastructure in order to detect the occurrence of new particle formation events on selected days in [Hyytiälä](http://sws.geonames.org/656888/), Finland. Detected events are then described, whereby we generate secondary (derivative) data about events. These data are stored to disk in CSV format.\n",
    "\n",
    "In addition, we use CSV on the Web to describe the secondary CSV data using common, shared terminology that is unambiguously identified and described on the web. This makes the secondary CSV data more interoperable, reusable and understandable to machines. For instance, we can use the description to transform the CSV data into RDF and then leverage SPARQL to query this data.\n",
    "\n",
    "Before we start, we need to install and load required Python modules as well as a few functions used in the workflow. Let's load first the required Python modules. Please execute the following (and all other) code blocks using `ALT+ENTER` or the `Run` button in the menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install csvwlib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, io, os, pandas as pd, numpy as np\n",
    "from urllib.parse import urlencode\n",
    "from pytz import timezone\n",
    "from datetime import datetime, timedelta\n",
    "from csvwlib import CSVWConverter\n",
    "from matplotlib import pyplot as plt\n",
    "from rdflib.plugins.sparql.results.csvresults import CSVResultSerializer\n",
    "\n",
    "def fetch(date):\n",
    "    time_from = timezone('Europe/Helsinki').localize(datetime.strptime(date, '%Y-%m-%d'))\n",
    "    time_to = time_from + timedelta(days=1)\n",
    "\n",
    "    query = {\n",
    "        'table': 'HYY_DMPS', 'quality': 'ANY', 'averaging': 'NONE', 'type': 'NONE',\n",
    "        'from': str(time_from), 'to': str(time_to), 'variables': 'd316e1,d355e1,d398e1,'\\\n",
    "        'd447e1,d501e1,d562e1,d631e1,d708e1,d794e1,d891e1,d100e2,d112e2,d126e2,d141e2,d158e2,'\\\n",
    "        'd178e2,d200e2,d224e2,d251e2,d282e2,d316e2,d355e2,d398e2,d447e2,d501e2,d562e2,d631e2,'\\\n",
    "        'd708e2,d794e2,d891e2,d100e3,d112e3,d126e3,d141e3,d158e3,d178e3,d200e3'\n",
    "    }\n",
    "    \n",
    "    url = 'https://avaa.tdata.fi/smear-services/smeardata.jsp?' + urlencode(query)\n",
    "    response = requests.post(url)\n",
    "\n",
    "    return pd.read_csv(io.StringIO(response.text))\n",
    "\n",
    "\n",
    "def plot(data):\n",
    "    d = data.copy(deep=True)\n",
    "    d = d.iloc[:, 6:].values\n",
    "    m = len(d)\n",
    "    n = len(d[0])\n",
    "    x = range(0, m)\n",
    "    y = range(0, n)\n",
    "    x, y = np.meshgrid(x, y)\n",
    "    z = np.transpose(np.array([row[1:] for row in d]).astype(np.float))\n",
    "    plt.figure(figsize=(10, 5), dpi=100)\n",
    "    plt.pcolormesh(x, y, z)\n",
    "    plt.plot((0, x.max()), (y.max()/2, y.max()/2), \"r-\")\n",
    "    plt.colorbar()\n",
    "    plt.xlim(right=m-1)\n",
    "    x_ticks = np.arange(x.min(), x.max(), 6)\n",
    "    x_labels = range(x_ticks.size)\n",
    "    plt.xticks(x_ticks, x_labels)\n",
    "    plt.xlabel('Hours')\n",
    "    y_ticks = np.arange(y.min(), y.max(), 6)\n",
    "    y_labels = ['3.16', '6.31', '12.6', '25.1', '50.1', '100']\n",
    "    plt.yticks(y_ticks, y_labels)\n",
    "    plt.ylabel('Diameter [nm]')\n",
    "    plt.ylim(top=n-1)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def query(q):\n",
    "    serializer = CSVResultSerializer(g.query(q))\n",
    "    output = io.BytesIO()\n",
    "    serializer.serialize(output)\n",
    "    return pd.read_csv(io.StringIO(output.getvalue().decode('utf-8')), encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also initialize two data structures we need to collect data about new particle formation events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['date', 'start', 'end', 'class']\n",
    "data = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Interpretation\n",
    "\n",
    "For a number of days, we fetch and plot particle size distribution data (primary data) as measured by the observation system. We provide several (example) days at which an event occurred. Please process some of the provided days. Your task is to record the start and end times as well as the classification of the event by looking at the visualization. We follow the classification scheme by [dal Maso et al.](http://www.borenv.net/BER/pdfs/ber10/ber10-323.pdf) consisting of three classes, namely Ia, Ib and II:\n",
    "\n",
    "* Class I: Days when the growth and formation rate can be determined with good confidence\n",
    "* Class Ia: Very clear and strong particle formation events\n",
    "* Class Ib: Other Class I events\n",
    "* Class II: Days where the derivation of these parameters is not possible or the accuracy of the results is questionable.\n",
    "\n",
    "You can of course also select days other than the ones suggested here. You could choose a day that follows one provided here and see how the visualized observational data differs. To guide you, we also provide example days at which no event occurred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Days to process\n",
    "#\n",
    "# Event days\n",
    "# 2007-04-15, 2007-05-05, 2007-05-18, 2007-10-19, 2008-02-19, 2009-03-19, 2009-03-22 \n",
    "# 2011-03-15, 2011-04-19, 2011-10-01, 2012-05-01, 2012-05-29, 2013-02-20, 2013-04-04\n",
    "#\n",
    "# Non Event days\n",
    "# 2007-04-20, 2008-02-20, 2009-04-03, 2011-04-21, 2012-05-05, 2013-02-21\n",
    "\n",
    "day = '2007-05-05'\n",
    "\n",
    "plot(fetch(day))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = '12:00'\n",
    "end = '13:30'\n",
    "# One of Ia, Ib or II\n",
    "classification = 'Ia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.append((day, start, end, classification))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(data, columns=labels)\n",
    "df.to_csv('data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME\n",
    "url = 'https://raw.githubusercontent.com/markusstocker/carbon-workshop/master/data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Column count in metadata does not match embedded metadata\n",
      "@prefix : <https://raw.githubusercontent.com/markusstocker/carbon-workshop/master/data.csv#> .\n",
      "@prefix as: <https://www.w3.org/ns/activitystreams#> .\n",
      "@prefix cc: <http://creativecommons.org/ns#> .\n",
      "@prefix csvw: <http://www.w3.org/ns/csvw#> .\n",
      "@prefix ctag: <http://commontag.org/ns#> .\n",
      "@prefix dc: <http://purl.org/dc/terms/> .\n",
      "@prefix dc11: <http://purl.org/dc/elements/1.1/> .\n",
      "@prefix dcat: <http://www.w3.org/ns/dcat#> .\n",
      "@prefix dcterms: <http://purl.org/dc/terms/> .\n",
      "@prefix dqv: <http://www.w3.org/ns/dqv#> .\n",
      "@prefix duv: <https://www.w3.org/TR/vocab-duv#> .\n",
      "@prefix foaf: <http://xmlns.com/foaf/0.1/> .\n",
      "@prefix gr: <http://purl.org/goodrelations/v1#> .\n",
      "@prefix grddl: <http://www.w3.org/2003/g/data-view#> .\n",
      "@prefix ical: <http://www.w3.org/2002/12/cal/icaltzd#> .\n",
      "@prefix ldp: <http://www.w3.org/ns/ldp#> .\n",
      "@prefix ma: <http://www.w3.org/ns/ma-ont#> .\n",
      "@prefix ns1: <http://purl.obolibrary.org/obo/> .\n",
      "@prefix oa: <http://www.w3.org/ns/oa#> .\n",
      "@prefix og: <http://ogp.me/ns#> .\n",
      "@prefix org: <http://www.w3.org/ns/org#> .\n",
      "@prefix owl: <http://www.w3.org/2002/07/owl#> .\n",
      "@prefix prov: <http://www.w3.org/ns/prov#> .\n",
      "@prefix qb: <http://purl.org/linked-data/cube#> .\n",
      "@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .\n",
      "@prefix rdfa: <http://www.w3.org/ns/rdfa#> .\n",
      "@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n",
      "@prefix rev: <http://purl.org/stuff/rev#> .\n",
      "@prefix rif: <http://www.w3.org/2007/rif#> .\n",
      "@prefix rr: <http://www.w3.org/ns/r2rml#> .\n",
      "@prefix schema: <http://schema.org/> .\n",
      "@prefix sd: <http://www.w3.org/ns/sparql-service-description#> .\n",
      "@prefix sioc: <http://rdfs.org/sioc/ns#> .\n",
      "@prefix skos: <http://www.w3.org/2004/02/skos/core#> .\n",
      "@prefix skosxl: <http://www.w3.org/2008/05/skos-xl#> .\n",
      "@prefix sosa: <http://www.w3.org/ns/sosa/> .\n",
      "@prefix ssn: <http://www.w3.org/ns/ssn/> .\n",
      "@prefix time: <http://www.w3.org/2006/time#> .\n",
      "@prefix v: <http://rdf.data-vocabulary.org/#> .\n",
      "@prefix vcard: <http://www.w3.org/2006/vcard/ns#> .\n",
      "@prefix void: <http://rdfs.org/ns/void#> .\n",
      "@prefix wdr: <http://www.w3.org/2007/05/powder#> .\n",
      "@prefix wdrs: <http://www.w3.org/2007/05/powder-s#> .\n",
      "@prefix xhv: <http://www.w3.org/1999/xhtml/vocab#> .\n",
      "@prefix xml: <http://www.w3.org/XML/1998/namespace> .\n",
      "@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\n",
      "\n",
      "<http://avaa.tdata.fi/2007-04-15> a ns1:ENVO_01001372 ;\n",
      "    ns1:OBI_0000999 <http://avaa.tdata.fi/class/Ia> ;\n",
      "    ns1:RO_0002537 \"11:00:00\"^^xsd:time ;\n",
      "    ns1:RO_0002538 \"12:00:00\"^^xsd:time ;\n",
      "    ns1:STATO_0000093 \"2007-04-15\"^^xsd:date .\n",
      "\n",
      "<http://avaa.tdata.fi/2007-05-05> a ns1:ENVO_01001372 ;\n",
      "    ns1:OBI_0000999 <http://avaa.tdata.fi/class/Ia> ;\n",
      "    ns1:RO_0002537 \"12:00:00\"^^xsd:time ;\n",
      "    ns1:RO_0002538 \"13:30:00\"^^xsd:time ;\n",
      "    ns1:STATO_0000093 \"2007-05-05\"^^xsd:date .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g = CSVWConverter.to_rdf(url, mode='minimal')\n",
    "\n",
    "print(g.serialize(format='ttl').decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-05-05</td>\n",
       "      <td>12:00:00</td>\n",
       "      <td>13:30:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date     start       end\n",
       "0  2007-05-05  12:00:00  13:30:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(query(\"\"\"\n",
    "PREFIX obo: <http://purl.obolibrary.org/obo/>\n",
    "PREFIX class: <http://avaa.tdata.fi/class/>\n",
    "SELECT ?date ?start ?end\n",
    "WHERE {\n",
    "  [] a obo:ENVO_01001372 ;\n",
    "    obo:OBI_0000999 ?class ;\n",
    "    obo:STATO_0000093 ?date ;\n",
    "    obo:RO_0002537 ?start ;\n",
    "    obo:RO_0002538 ?end .\n",
    "  FILTER (?class = class:Ia)\n",
    "  FILTER (?date > \"2007-05-01\"^^xsd:date)\n",
    "}\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
